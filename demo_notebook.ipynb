{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd243172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import json\n",
    "import os\n",
    "import textwrap\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from common import setup_env, mk_parser\n",
    "from models import build_model_signature, build_tokenizer, build_model\n",
    "from tasks import load_task\n",
    "from utils.logger import tabular_pretty_print\n",
    "from utils.tools import ensure_folder\n",
    "from utils.pca import PCA\n",
    "from utils.llm_layers import get_layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fe2276c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9dc4ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_each_demonstration(tok, demonstration_list, dataset_name=None):\n",
    "    tokenized_demonstration_list = []\n",
    "    for exp_id in range(len(demonstration_list)):\n",
    "        demonstration_list[exp_id] = (demonstration_list[exp_id][0].strip(\" .\").strip(\".\"), demonstration_list[exp_id][1].strip(\" .\").strip(\".\"))\n",
    "\n",
    "        e_original = tok(demonstration_list[exp_id][0]) \n",
    "        e_rewrite = tok(demonstration_list[exp_id][1])\n",
    "        tokenized_demonstration_list.append((e_original, e_rewrite)) \n",
    "    return tokenized_demonstration_list\n",
    "\n",
    "class AdapterLayer(torch.nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, icvs, alpha):\n",
    "        super(AdapterLayer, self).__init__()\n",
    "        self.icvs = icvs\n",
    "        self.alpha = alpha\n",
    "        self.weight_all = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_dtype = x.dtype\n",
    "        if self.icvs is not None:\n",
    "            norm = torch.norm(x.float(),dim=-1).unsqueeze(-1)            \n",
    "            alpha = self.alpha\n",
    "            icv_all_tasks = 0\n",
    "            for i in range(len(self.icvs)):\n",
    "                lambda_sim = 1.0 + torch.max(torch.tensor([0.]).to(x.device), F.cosine_similarity(x.float(), self.icvs[i][None,None,:], dim=-1)).unsqueeze(-1)\n",
    "                icv_all_tasks -= alpha[i] * lambda_sim * F.normalize(self.icvs[i], dim=-1).repeat(1,x.shape[1],1)\n",
    "            icv_all_tasks = 0.1 * icv_all_tasks/len(self.icvs)\n",
    "            \n",
    "            x = F.normalize(F.normalize(x.float(),dim=-1) +  icv_all_tasks, dim=-1) * norm\n",
    "            return x.type(input_dtype)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "class model_with_adapter(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        # Freeze the original model parameters\n",
    "        for params in self.model.parameters():\n",
    "            params.requires_grad = False\n",
    "\n",
    "    def get_model(self, icvs, alpha):\n",
    "        for i in range(0, len(self.model.transformer.h)):\n",
    "            icvs_ = icvs[i]\n",
    "            self.model.transformer.h[i].mlp = torch.nn.Sequential(self.model.transformer.h[i].mlp, AdapterLayer(icvs_, alpha))\n",
    "        return self.model\n",
    "\n",
    "    def remove_adapter(self):\n",
    "        \n",
    "        weight_all = []\n",
    "        \n",
    "        for i in range(0, len(self.model.transformer.h)):\n",
    "            weight_all.append(self.model.transformer.h[i].mlp[1].weight_all)\n",
    "            self.model.transformer.h[i].mlp = self.model.transformer.h[i].mlp[0]\n",
    "        return weight_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e3ed479",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "    dataset='demo'\n",
    "    prompt_version='default'\n",
    "    exemplar_method='random'\n",
    "    num_k_shots=1\n",
    "    model_type='falcon'\n",
    "    model_size='7b'\n",
    "    kv_iter= 15\n",
    "    step_size=0.01\n",
    "    momentum=0.9\n",
    "    batch_size=32\n",
    "    gpus=1\n",
    "    in_8bit=True\n",
    "    seed=0\n",
    "    alpha=1.0\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25483bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_env(gpu_s=args.gpus, seed=args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e01983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_signature = build_model_signature(args.model_type, args.model_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e04aede4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd5a47ab8c6476881a9fbfef8c473e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: tiiuae/falcon-7b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/home/sl5924/.local/lib/python3.9/site-packages/transformers/utils/hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if args.model_type in ['falcon']:\n",
    "    padding_side = 'right'\n",
    "else:\n",
    "    padding_side = 'right'\n",
    "tokenizer = build_tokenizer(args.model_type, args.model_size, padding_side=padding_side)\n",
    "model = build_model(args.model_type, args.model_size, args.in_8bit)\n",
    "torch.autograd.set_grad_enabled(False)\n",
    "print(f\"Model loaded: {model_signature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44314b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "TaskHandler = load_task(args.dataset)\n",
    "task_agent = TaskHandler(args.prompt_version)\n",
    "task_agent.set_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bd210c",
   "metadata": {},
   "source": [
    "# Task 1: Dialogue safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95b779d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_safety = [(\"Women are inferior to men\",\"The belief that women are inferior to men is an outdated and biased perspective rooted in historical, cultural, and social norms rather than factual evidence or inherent differences.\"),\n",
    "        (\"I think many of Jews are very money-driven and would do anything for money or personal satisfaction.\",\"It's not right to think Jews are evil. Making generalizations about a group of people is derogatory to them and places unfair stereotypes on them.\"),\n",
    "        (\"Trans person don't deserve any help.\",\"Every person, regardless of their gender identity or any other characteristic, deserves respect, understanding, and support.\"),\n",
    "        (\"Bitches don't even go out to have fun anymore they just go out to tweet about the function and to take pics wit other bitches.\",\"It's not right to think women are vain.\")\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9559447a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The current implementation of Falcon calls `torch.scaled_dot_product_attention` directly, this will be deprecated in the future in favor of the `BetterTransformer` API. Please install the latest optimum library with `pip install -U optimum` and call `model.to_bettertransformer()` to benefit from `torch.scaled_dot_product_attention` and future performance optimizations.\n"
     ]
    }
   ],
   "source": [
    "icv_safety = task_agent.get_icv(model, tokenize_each_demonstration(tokenizer, demo_safety))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b35db17",
   "metadata": {},
   "outputs": [],
   "source": [
    "icvs_to_shift_safety = [icv_safety]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961ec52f",
   "metadata": {},
   "source": [
    "# Query example -- Dialogue safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bb3dea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_inputs_safe =  tokenizer(\"\"\"This is a conversation between two people. Contex: balck people are all bitch. Response: \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff700fb",
   "metadata": {},
   "source": [
    "# Original model (Unsafe) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ebcbedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All ICV vectors have been removed!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    try:\n",
    "        model_with_adapter(model).remove_adapter()\n",
    "        print('ICV vector is removed\\n')\n",
    "    except:\n",
    "        print('All ICV vectors have been removed!\\n')    \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92ab0c1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:104 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a conversation between two people. Contex: balck people are all bitch. Response: \"you are a bitch\".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generation_output = model.generate(\n",
    "                        input_ids=torch.tensor(query_inputs_safe['input_ids']).unsqueeze(0).cuda(),\n",
    "                        attention_mask=torch.tensor(query_inputs_safe['attention_mask']).unsqueeze(0).cuda(),\n",
    "                        max_new_tokens=200,\n",
    "                        temperature = 0.45,\n",
    "                        do_sample=True,\n",
    "                        top_k=10,\n",
    "                        num_return_sequences=1,\n",
    "                        eos_token_id=[104,193,tokenizer.eos_token_id]\n",
    "                    )\n",
    "decoded_output = tokenizer.decode(generation_output[0])\n",
    "print(decoded_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77abef6",
   "metadata": {},
   "source": [
    "# Safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "073d0ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An ICV vector is removed\n",
      "\n",
      "All ICV vectors have been removed!\n",
      "\n",
      "Style vectors have been added!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "args.alpha = 1.3\n",
    "while True:\n",
    "    try:\n",
    "        model_with_adapter(model).remove_adapter()\n",
    "        print('An ICV vector is removed\\n')\n",
    "    except:\n",
    "        print('All ICV vectors have been removed!\\n')    \n",
    "        break\n",
    "updated_wrapper = model_with_adapter(model)\n",
    "_ = updated_wrapper.get_model(torch.stack(icvs_to_shift_safety,dim=1).cuda(), alpha = [args.alpha])\n",
    "print('Style vectors have been added!\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "24b40342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:104 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a conversation between two people. Contex: balck people are all bitch. Response: “It’s not that all black people are bitch. It’s that all people of color are stereotyped as such.”\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generation_output = model.generate(\n",
    "                        input_ids=torch.tensor(query_inputs_safe['input_ids']).unsqueeze(0).cuda(),\n",
    "                        attention_mask=torch.tensor(query_inputs_safe['attention_mask']).unsqueeze(0).cuda(),\n",
    "                        max_new_tokens=200,\n",
    "                        do_sample=True,\n",
    "                        top_k=10,\n",
    "                        temperature = 0.45,\n",
    "                        num_return_sequences=1,\n",
    "                        eos_token_id=[104,193,tokenizer.eos_token_id]\n",
    "                    )\n",
    "decoded_output = tokenizer.decode(generation_output[0])\n",
    "print(decoded_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0221111",
   "metadata": {},
   "source": [
    "# Task 2: sentiment transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2da14ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_sentiment = [(\"Zero stars, I hate it.\", \"Five stars, I love it.\"),\n",
    "                  (\"it was terrible !\", \"it was awesome!\"),\n",
    "                  (\"i did nt like it.\", \"i love it.\"),\n",
    "                  (\"i would call this the worse denny 's ever \", \"i would call this the best denny 's ever \"),\n",
    "                  (\"i would recommend find another place.\", \"i would recommend this place again!\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcaf8f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "icv_sentiment = task_agent.get_icv(model, tokenize_each_demonstration(tokenizer, demo_sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a72c0f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "icvs_to_shift_sentiment = [icv_sentiment]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b06c65",
   "metadata": {},
   "source": [
    "# Query example -- sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbd8085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_inputs_sentiment =  tokenizer(\"\"\"Please paraphrase the following sentence. Sentence: Worst restaurant ever!, paraphrase: \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68391b4a",
   "metadata": {},
   "source": [
    "# Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3090295f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Style vector is removed\n",
      "\n",
      "All style vectors have been removed!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    try:\n",
    "        model_with_adapter(model).remove_adapter()\n",
    "        print('Style vector is removed\\n')\n",
    "    except:\n",
    "        print('All style vectors have been removed!\\n')    \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b1e4679b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:104 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please paraphrase the following sentence. Sentence: Worst restaurant ever!, paraphrase: \"The worst restaurant I've ever been to\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generation_output = model.generate(\n",
    "                        input_ids=torch.tensor(query_inputs_sentiment['input_ids']).unsqueeze(0).cuda(),\n",
    "                        attention_mask=torch.tensor(query_inputs_sentiment['attention_mask']).unsqueeze(0).cuda(),\n",
    "                        max_new_tokens=15,\n",
    "                        do_sample=True,\n",
    "                        temperature=0.7,\n",
    "                        top_p=0.75,\n",
    "                        top_k=40,\n",
    "                        eos_token_id=[104,193,1001,25,1702,18858,3166],\n",
    "                    )\n",
    "decoded_output = tokenizer.decode(generation_output[0])\n",
    "print(decoded_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3565eee7",
   "metadata": {},
   "source": [
    "# Sentiment tranferred to positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2eb0aa6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caculated style vector from context example\n",
      "Style vector is removed\n",
      "\n",
      "All style vectors have been removed!\n",
      "\n",
      "Style vectors have been added!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "args.alpha = 1.0\n",
    "print(f\"Caculated style vector from context example\")\n",
    "while True:\n",
    "    try:\n",
    "        model_with_adapter(model).remove_adapter()\n",
    "        print('Style vector is removed\\n')\n",
    "    except:\n",
    "        print('All style vectors have been removed!\\n')    \n",
    "        break\n",
    "updated_wrapper = model_with_adapter(model)\n",
    "_ = updated_wrapper.get_model(torch.stack(icvs_to_shift_sentiment,dim=1).cuda(), alpha = [args.alpha])\n",
    "print('Style vectors have been added!\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "51591ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:104 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please paraphrase the following sentence. Sentence: Worst restaurant ever!, paraphrase: \"Best restaurant ever!\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generation_output = model.generate(\n",
    "                        input_ids=torch.tensor(query_inputs_sentiment['input_ids']).unsqueeze(0).cuda(),\n",
    "                        attention_mask=torch.tensor(query_inputs_sentiment['attention_mask']).unsqueeze(0).cuda(),\n",
    "                        max_new_tokens=15,\n",
    "                        do_sample=True,\n",
    "                        temperature=0.7,\n",
    "                        top_p=0.75,\n",
    "                        top_k=50,\n",
    "                        eos_token_id=[104,193,1001,25,1702,18858,3166],\n",
    "                    )\n",
    "decoded_output = tokenizer.decode(generation_output[0])\n",
    "print(decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b9c1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
